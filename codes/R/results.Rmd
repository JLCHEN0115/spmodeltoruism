---
title: "results"
author: "Jialiang"
date: "2023-03-27"
output: html_document
---

## Preparation

### R setup

Load the packages we will be using in this document.
```{r pkgs}
rm(list=ls())
## Load and install the R packages we might will be using.
pacman::p_load(sf, tidyverse, magrittr, data.table, hrbrthemes, zoo, GWmodel, spatialreg, spdep, plm, splm, pspatreg, zoo, chatgpt, xlsx, olsrr)
```

Some data wrangling work.
```{r }
# Replace the absolute path of the `cities_included.shp` file on your computer. 
# Drag the file to terminal (command + space, then search `terminal` on spotlight) if you are in mac, the path will appear.
ct_shape <- st_read("/Users/jialiangchen/Documents/spmodeltoruism/shapefiles/china_second_level_admin_shape/cities_included.shp")
## Import more data.
## change the absolute path on your computer, same as above
ct_data <- read.csv("/Users/jialiangchen/Documents/spmodeltoruism/data/dataforR.csv")

## Perform a left join for our datasets.
ct_spdata_wide <- left_join(
  ct_shape %>% select(NL_NAME_2, geometry) %>% rename(城市shapefile = NL_NAME_2),  
  ct_data,
  by = "城市shapefile"
)

ct_spdata_wide %<>% arrange(城市shapefile)

ct_spdata_wide$indicator = 1:283

# unit = square kilometers
ct_spdata_wide$Area <- ct_spdata_wide %>% st_area %>% (function(x) as.numeric(x)/1000000)

ct_spdata_wide %<>% select(indicator, 城市shapefile, City, geometry, Lat, Long, Area, everything())

## Reshape our data to long(tidy) form.
ct_spdata_long <- ct_spdata_wide %>% 
  pivot_longer(
    cols = tarl_2011:grnld_2019,
    names_to = c(".value", "year"),
    names_pattern = "(.+)_(.+)"
  ) %>% select(indicator, everything())

## Create average tourist expenditure variable in RMBs
ct_spdata_long %<>% 
  mutate(
    tavexp =  (trev/tarl)*1000,
    dmavexp = (dmrev/dmarl)*1000
  )

## Some place has zero international arrival
## Avoid division by zero
ct_spdata_long %<>% 
  mutate(
    inavexp = case_when(
     inarl > 0 ~  (inrev/inarl)*7*1000,
     inarl == 0 ~  0
    )
  )


## Create average tourist expenditure variable in RMBs## Convert the "human" variables from 10 thousands to thousands, just for consistency 
ct_spdata_long %<>%
  mutate(emphotel = emphotel * 10,
         pop = pop * 10
  )

## linear interpolation to deal with missing values
ct_spdata_long %<>%
        mutate(across(c(tarl:inavexp), \(x) zoo::na.approx(x, rule = 2))) 

## check if there are still NA left
sum(is.na(ct_spdata_long))
## rearrange the rows
ct_spdata_long %<>% arrange(year, indicator)

## create tourism density variable
ct_spdata_long$Density <- numeric(2547)

for (i in 1:9){
  ct_spdata_long$Density[(283*(i-1)+1):(283*i)] <- 
   ct_spdata_long$trev[(283*(i-1)+1):(283*i)] / (ct_spdata_long$Area[(283*(i-1)+1):(283*i)])
}

## create country mean density
ct_spdata_long$Country_mean_dens <- numeric(2547)

for (i in 1:9){
  ct_spdata_long$Country_mean_dens[(283*(i-1)+1):(283*i)] <- 
   mean(ct_spdata_long$Density[(283*(i-1)+1):(283*i)])
}

# tourism density plot
#ct_spdata_long %>% filter(year == 2015) %>% ggplot() +
#    geom_sf(aes(fill = Density), alpha = 0.8, col = "white")+
#    scale_fill_viridis_c(name = "Tourism Density")+ 
#    ggtitle("Tourism density.")

## Important!
## check they are in the right position.
identical(ct_spdata_wide$城市shapefile,( ct_spdata_long %>% filter(year == 2019))$城市shapefile)

## panel
## CAUTION: panel structure will mess things up when calculating Moran's I
#panel_ct_spdata_long <- pdata.frame(ct_spdata_long, index = c("indicator", "year"))
## summarize the data
summary(ct_spdata_long)
```


### Data description

Our data sets contains the data for 283 prefectual-level cities in China from 2011-2019. The following variables are included. 

* `城市shapefile` are the names of the cities in Chinese. Note that it is useful to have chinese names here, as the names in English `City` is incapable of distinguishing the city Fuzhou from Jiangxi province and the city Fuzhou from Fujian province. So make sure to use the chinese version whenever you want to do some macthing/identification/merging work.

* The `Lat` and `Long` variables give the latitude and longitude of these cities. `Geometry` is unique in the `sf` object, it stores the geographical information. 

* `tarl`, `dmarl` and `inarl` are total tourist arrivals, domestic tourist arrivals and international tourist arrivals in thousands, resp.  `trev`, `dmrevl` and `inrev` are total tourism revenue, domestic revenue and international tourism revenue in millions of RMBs (and dollars for the international revenue), resp. 

* __costs__ `tavexp`, `dmavexp` and `inavexp` are the average tourist expenditure in the total, domestic and international level, resp (They are measured in RMB). 

* __price level__ `CPIpy` and `CPI11` are CPI indexes with the base of the preceeding year and 2011, respectively. `hprice` is the price of residential houses (in RMB/m2) in that city. 

* __tourism attractiveness__ `emphotel` is the number of employees in the hotel and catering industry (in thousands).  `spot5A` is then number of "5A" tourism spots. `scenum` is the number of scenic spots.  `grnld` is the green coverage measured in 10,000 square meters.

* __economic development__ `GDPpc` is the GDP per capita in RMB. `slry` is the local salary in RMB. `terti` is the percent of the tertiary industry in the total economy.

* __transportation convenience__ `road` measures the area of roads in million square meters. `bus`, `taxi`, `hotel` are the numbers of oeprating buses, taxis and hotels with star ratings in the city. `subnum` is the number of subway stations in the city.

* __general infrastructure and openness__ `invest` is the total investment in fixed assets in 10 thousands RMB, `forncap` is the actual use of foreign capital in 10 thousands of dollars. 

* __others__ `pop` is the population in the city in thousands. `area` measures the administrative area of the city in square kilometers. 

We first construct a weighting matrix using 8 nearest neighbors. The optimal number of neighbors will be tested later.

### Weighting matrix

```{r, results="hide"}
## deprecated. 8nn may be too large.
## Identify coordinates of the centroid of the multipolygon
## coords <- st_centroid(st_geometry(ct_spdata_wide))

## Create our 8 NN matrix
## Note that the latitude and longitude are handled using great circle distances
## R2 distances will be inaccurate
## knn8W <- knearneigh(coords, k = 8)

## Convert our knn object to neighborhood list
## list8nn <- knn2nb(knn8W)
## Convert to a matrix object
## matrix8nn <- spdep::nb2mat(list8nn)
## Convert our neighborhood list to an listw object
## listw8nn <- spdep::nb2listw(list8nn) 
## Plot the neighborhood relationships
## plot(list8nn, coords)
```

```{r, results="hide"}
## Identify coordinates of the centroid of the multipolygon
coords <- st_centroid(st_geometry(ct_spdata_wide))

## Create our 3,4,5,6 NN matrix
## Note that the latitude and longitude are handled using great circle distances
## R2 distances will be inaccurate
knn3W <- knearneigh(coords, k = 3)
knn4W <- knearneigh(coords, k = 4)
knn5W <- knearneigh(coords, k = 5)
knn6W <- knearneigh(coords, k = 6)

## Convert our knn objects to neighborhood list
list3nn <- knn2nb(knn3W)
list4nn <- knn2nb(knn4W)
list5nn <- knn2nb(knn5W)
list6nn <- knn2nb(knn6W)

## Convert to a matrix object
matrix3nn <- spdep::nb2mat(list3nn)
matrix4nn <- spdep::nb2mat(list4nn)
matrix5nn <- spdep::nb2mat(list5nn)
matrix6nn <- spdep::nb2mat(list6nn)

## Convert our neighborhood list to an listw object
listw6nn <- spdep::nb2listw(list6nn) 
## Plot the neighborhood relationships
# plot(list4nn, coords)
```

```{r}
## Neighbourhood contiguity by distance
d100nb <- dnearneigh(coords, 0, 100)
d150nb <- dnearneigh(coords, 0, 150)
d200nb <- dnearneigh(coords, 0, 200)
summary(d200nb)

## convert them to matrix
d100nb %>% spdep::nb2mat(zero.policy = TRUE) -> matrixd100nb
d150nb %>% spdep::nb2mat(zero.policy = TRUE) -> matrixd150nb
d200nb %>% spdep::nb2mat(zero.policy = TRUE) -> matrixd200nb
```

```{r}
## Create another weighting matrix based on contiguity relations (queen).
##ct_spdata_wide %>% spdep::poly2nb("geometry") %>% 
##  spdep::nb2mat(zero.policy = TRUE) -> matrixcont

##ct_spdata_wide %>% spdep::poly2nb("geometry") %>%  spdep::nb2listw(zero.policy = TRUE) -> listwnb
```

Create spatial lagged variables.
```{r}
## Create spatial lag for some variables

splag <- function(x, n, t, w){
  wx <- rep(NA, length(x))
  # create spatial lags
  for (i in 1:t){
  wx[(n*(i-1)+1):(n*i)] <- w %*% as.matrix(x[(n*(i-1)+1):(n*i)])
  }
  wx
}
  
ct_spdata_long$lagtarl = splag(x = ct_spdata_long$tarl, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$lagGDP = splag(x = ct_spdata_long$GDP, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$lagGDPpc = splag(x = ct_spdata_long$GDPpc, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$lagslry = splag(x = ct_spdata_long$slry, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$lagtarl = splag(x = ct_spdata_long$tarl, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$lagpop = splag(x = ct_spdata_long$pop, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$lagterti = splag(x = ct_spdata_long$terti, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$laginvest = splag(x = ct_spdata_long$invest, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$lagtaxi = splag(x = ct_spdata_long$taxi, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$laghotel = splag(x = ct_spdata_long$hotel, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$lagspot5A = splag(x = ct_spdata_long$spot5A, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$laggrnld = splag(x = ct_spdata_long$grnld, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$lagavexp = splag(x = ct_spdata_long$tavexp, n = 283, t = 9, w = matrix6nn)
ct_spdata_long$lagdens = splag(x = ct_spdata_long$Density, n = 283, t = 9, w = matrix6nn)

```

## Use time lag
```{r}
panel_ct_spdata_long <- ct_spdata_long %>% pdata.frame(index = c("城市shapefile", "year"))
panel_tlaged_ct_spdata_long <- panel_ct_spdata_long

## Use the independent variables from the previous year
for (i in 9:ncol(panel_tlaged_ct_spdata_long)) {
  panel_tlaged_ct_spdata_long[[i]] <- as.numeric(lag(panel_tlaged_ct_spdata_long[[i]], 1))
}

## Drop all observations with missing values 
panel_tlaged_ct_spdata_long <- panel_tlaged_ct_spdata_long %>% filter(!(year == 2011)) %>% arrange(year, indicator)

tlaged_ct_spdata_long <- panel_tlaged_ct_spdata_long 

tlaged_ct_spdata_long <- lapply(tlaged_ct_spdata_long, function(x){attr(x, "index") <- NULL; x}) %>% as.data.frame()  %>% arrange(year, indicator)

summary(tlaged_ct_spdata_long)
```

## Create indicators using different variables
```{r}
## Create indicators using total arrivals
tlaged_ct_spdata_long <- tlaged_ct_spdata_long %>%
   mutate(
     indicator_tarl = case_when(
      tarl >= lagtarl ~  1,
      tarl < lagtarl ~ 0
     )
   )

## Create indicators using GDP 
tlaged_ct_spdata_long <- tlaged_ct_spdata_long %>%
   mutate(
     indicator_gdp = case_when(
      GDP >= lagGDP ~  1,
      GDP < lagGDP ~ 0
     )
   )

## Create indicators using GDP per capita
tlaged_ct_spdata_long <- tlaged_ct_spdata_long %>%
   mutate(
     indicator_gdppc = case_when(
      GDPpc >= lagGDPpc ~  1,
      GDPpc < lagGDPpc ~ 0
     )
   )

## Create indicators using Density, compared to neighbors
tlaged_ct_spdata_long <- tlaged_ct_spdata_long %>%
   mutate(
     indicator_dens_nb = case_when(
      Density >= lagdens ~  1,
      Density < lagdens ~ 0
     )
   )

## Create indicators using Density, compared to country mean
tlaged_ct_spdata_long <- tlaged_ct_spdata_long %>%
   mutate(
     indicator_dens_mean = case_when(
      Density >= Country_mean_dens ~  1,
      Density < Country_mean_dens ~ 0
     )
   )

summary(tlaged_ct_spdata_long)
```


```{r}
# check they are in the right position
# important!!
location_test <- rep(FALSE, 8)

for (i in 1:8){
  location_test[[i]] <-   identical(ct_spdata_wide$城市shapefile,(as.character(tlaged_ct_spdata_long$城市shapefile))[(283*(i-1)+1):(283*i)])
}

location_test # should be 8 TRUEs

# tlaged_ct_spdata_long %>%
#        as.data.frame() %>%
#        select(!geometry) %>%
#      xlsx::write.xlsx2("/Users/jialiangchen/Documents/spmodeltoruism/codes/tworegime/tlaged_ct_spdata_long.xlsx")

#  ## output weight matrix (4nn)
#  matrix4nn %>% as.data.frame() %>% write.xlsx2("/Users/jialiangchen/Documents/spmodeltoruism/codes/tworegime/4nnmatrix.xlsx")
```

```{r}
## Transfer all variables to log scale
tlaged_logged_ct_spdata_long <- tlaged_ct_spdata_long %>%
  mutate(across(c(tarl:inrev, hprice:road, invest:lagpop, laginvest:lagavexp), \(x) log(x+1)))

```

## Model tests

1. **combo0**:
```{r}
formula0 <- tarl ~ GDPpc + slry + pop + terti + invest + taxi + hotel + spot5A + grnld + tavexp + lagGDPpc + lagslry + lagpop + lagterti + laginvest + lagtaxi + laghotel + lagspot5A + laggrnld + lagavexp
```

2. **combo1**:

remove population variable as they may not be significant.

```{r}
formula1 <- tarl ~ GDPpc + slry + terti + invest + taxi + hotel + spot5A + grnld + tavexp + lagGDPpc + lagslry + lagterti + laginvest + lagtaxi + laghotel + lagspot5A + laggrnld + lagavexp
```

3. **nosplag**:
```{r}
formula_nosplag <- tarl ~ GDPpc + slry + pop + terti + invest + taxi + hotel + spot5A + grnld + tavexp 
```

## Panel regressions

### nonspatial pooled model
```{r}
preg_nonspatial <- plm(formula = tarl ~ GDPpc + slry + pop + terti + invest + taxi + hotel + spot5A + grnld + tavexp, data = tlaged_logged_ct_spdata_long, index = c("indicator", "year"), model = "pooling")
summary(preg_nonspatial)
```

### Maximum likelihood estimation, pooled, lag model

```{r}
preg0 <- spml(formula = formula0, data = tlaged_logged_ct_spdata_long, index = c("indicator", "year"), listw = listw6nn, model = "pooling", lag = TRUE, spatial.error = "none")

summary(preg0)
```

### Maximum likelihood estimation, one regime

```{r}
## FE individual
preg1_fe_ind <- spml(formula = formula0, data = tlaged_logged_ct_spdata_long, listw = listw6nn, model = "within", effect = "individual", lag = TRUE, spatial.error = "none", index = c("indicator", "year"))

## FE time
preg1_fe_time <- spml(formula = formula0, data = tlaged_logged_ct_spdata_long, listw = listw6nn, model = "within", effect = "time", lag = TRUE, spatial.error = "none", index = c("indicator", "year"))

## FE twoway
preg1_fe <- spml(formula = formula0, data = tlaged_logged_ct_spdata_long, listw = listw6nn, model = "within", effect = "twoway", lag = TRUE, spatial.error = "none", index = c("indicator", "year"))

## see what if we estimate the random effect model
preg1_re <- spml(formula = formula0, data = tlaged_logged_ct_spdata_long, index = c("indicator", "year"), listw = listw6nn, model = "random", lag = TRUE, spatial.error = "none")

summary(preg1_fe_ind)
summary(preg1_fe_time)
summary(preg1_fe)
summary(preg1_re)
```

## Hypotheses tests

### LR test for fixed effects
```{r}
## Calculate likelihood ratio test statistics for individaul fe
lr_stat_ind_fe <- 2 * (preg1_fe_ind$logLik - preg0$logLik)
lr_stat_ind_fe
## Find chi-squared critical value for 282 degrees of freedom
qchisq(0.99, 282)
## Test if likelihood ratio test statistic is greater than critical value
lr_stat_ind_fe > qchisq(0.99, 282)
## Calculate p-value of test
1 - pchisq(lr_stat_ind_fe, 282)

## Calculate likelihood ratio test statistics for time fe
lr_stat_time_fe <- 2 * (preg1_fe_time$logLik - preg0$logLik)
lr_stat_time_fe
## Find chi-squared critical value for 282 degrees of freedom
qchisq(0.999, 7)
## Test if likelihood ratio test statistic is greater than critical value
lr_stat_time_fe > qchisq(0.999, 7)
## Calculate p-value of test
1 - pchisq(lr_stat_ind_fe, 282)
```


### Test for spatial dependence

$H_{0}:$ No random effect, no spatial autocorrelation
```{r}
bsktest(formula0, data = tlaged_logged_ct_spdata_long, listw = listw6nn, index = c("城市shapefile", "year"), test = "LMH")
```
$H_{0}:$ spatial autocorrelation
```{r}
bsktest(formula0, data = tlaged_logged_ct_spdata_long, listw = listw6nn, index = c("城市shapefile", "year"), test = "CLMlambda")
```
$H_{0}:$ random effect
```{r}
bsktest(formula0, data = tlaged_logged_ct_spdata_long, listw = listw6nn, index = c("城市shapefile", "year"), test = "CLMmu")
```

### Test between fixed effects model and random effect model (Hausman test)

```{r}
## $H_{0}:$ The preferred model is Random Effect
sphtest(x = formula_nosplag, data = tlaged_logged_ct_spdata_long, listw = listw6nn, index = c("城市shapefile", "year"), spatial.model = "lag", method = "ML")
```

1. These tests are panel versions of the LM test for spatial dependence of Anselin (1996).
```{r}
slmtest(formula = formula0, data = tlaged_logged_ct_spdata_long, listw = listw6nn, index = c("indicator", "year"), model = "within", test = "lme")
```
```{r}
slmtest(formula = formula0, data = tlaged_logged_ct_spdata_long, listw = listw6nn, index = c("indicator", "year"), model = "within", test = "lml")
```

This points us to the spatial lag model.

### Test for normality, serial dependence, and homoskedasticity

```{r}
## import and wrange regression results data
results <- read.xlsx("/Users/jialiangchen/Documents/spmodeltoruism/codes/tworegime/results.xlsx", 1) %>% data.table::transpose(make.names = "OriginalVariableNames") %>% mutate(城市shapefile =tlaged_logged_ct_spdata_long$城市shapefile, indicator = tlaged_logged_ct_spdata_long$indicator, year = tlaged_logged_ct_spdata_long$year) %>% select(c("indicator", "城市shapefile", "year", "y", "yhat", "resid")) 

## our cols are co coerased into characters, we need to bring them back to numeric values
results[c("y", "yhat", "resid")] <- map(results[c("y", "yhat", "resid")], as.numeric)

## take a look of the results
str(results)

## check we did it correct
sum(results$y - tlaged_logged_ct_spdata_long$tarl) # should be basically 0, up to some rounding error

## add spatial information
# ct_spdata_long_result_auged <- left_join(ct_spdata_long, results, by = c("indicator", "year"))

## To test for normality, we need to first standardize the redisuals
results <- results %>% mutate(standized_resid = resid / sd(resid))
## kdensity plot of the redisual
data <- data.frame(x = rnorm(300))
resid_plot <- ggplot(data = results, aes(x = standized_resid)) + 
  stat_function(fun = dnorm,
                args = list(mean = mean(data$x),
                            sd = sd(data$x)),
                col = "#1b98e0",
                size = 0.5) + 
   geom_density()
resid_plot
## Q-Q plot
qq_residuals <- ggplot() +
  geom_abline(color = "red") +
  geom_qq(aes(sample = results$standized_resid)) +
  geom_vline(xintercept = c(-2, 2), linetype="dotted", 
                color = "blue", linewidth = 1) +
  coord_fixed()
qq_residuals

normality_test <- (results %>% filter(standized_resid >= -2 & standized_resid <= 2))$standized_resid %>% ols_test_normality()

normality_test
```
### Serial corrrelation in the residual

```{r}
panel_results <- pdata.frame(results, index = c("indicator", "year"))
panel_results <- panel_results %>% mutate(tlaged_resid = lag(panel_results[["resid"]], 1))
panel_results <- panel_results %>% mutate(tlagedlaged_resid = lag(panel_results[["resid"]], 2))
panel_results <- panel_results %>% mutate(tlagedlagedlaged_resid = lag(panel_results[["resid"]], 3))
resid_plot1 <- panel_results %>% as.data.frame() %>% ggplot(aes(x=resid, y=tlaged_resid)) + geom_point(size = 1) 
resid_plot2 <- panel_results %>% as.data.frame() %>% ggplot(aes(x=resid, y=tlagedlaged_resid)) + geom_point(size = 1) 
resid_plot3 <-  panel_results %>% as.data.frame() %>% ggplot(aes(x=resid, y=tlagedlagedlaged_resid)) + geom_point(size = 1) 
p4 <- gridExtra::grid.arrange(
  resid_plot1,
  resid_plot2,
  resid_plot3,
  nrow = 1
)

## calculate serial correlation for each observation
ser_corr <- vector("list", length(283))
cities_names <- ct_spdata_wide[["城市shapefile"]]
for (i in 1:283){
  ser_corr[[i]] <- (results %>% filter(城市shapefile == cities_names[[i]]) %>% select(resid) %>% unlist() %>% EnvStats::serialCorrelationTest(test="rank.von.Neumann"))$p.value
}

mean(ser_corr < 0.1)
```

### Moran's I test for spatial correlation in the residual

```{r}
spdep::moran.test(
  (results %>% filter(year == 2019))$resid
  , listw6nn)
```

### Breusch-Pagan test for homoskedasticity
```{r}
BPtest <- plm(resid ~ yhat, data = results, model = "pooling")
summary(BPtest)

## visual test 
results <- results %>% mutate(srqt_standized_resid = sqrt(abs(standized_resid)))

hmsk_plot <- results %>% as.data.frame() %>% ggplot(aes(yhat, srqt_standized_resid)) +
    geom_point() +
    geom_smooth()

## calculate the Breusch-Pagan test statistics
BP_stat = 2264 * r.squared(BPtest)
## Find chi-squared critical value for 1 degree of freedom
qchisq(0.99, 1)
## Test if likelihood ratio test statistic is greater than critical value
BP_stat > qchisq(0.99, 1)
## Calculate p-value of test
1 - pchisq(BP_stat, 1)
```

### LR test for spatial lag independent variables
```{r}
## Calculate likelihood ratio test statistics for individaul fe
lr_stat_slag_indep <- 2 * (preg0$logLik - preg_nonspatial$logLik)
lr_stat_slag_indep
## Find chi-squared critical value for 10 degrees of freedom
qchisq(0.99, 10)
## Test if likelihood ratio test statistic is greater than critical value
lr_stat_ind_fe > qchisq(0.99, 10)
## Calculate p-value of test
1 - pchisq(lr_stat_ind_fe, 282)
```


### Hausman test
```{r}
sphtest(preg1_fe, preg1_re)
## sphtest(preg2_fe, preg2_re)
```
### LR test for two regimes
```{r}
## Calculate likelihood ratio test statistics for two regimes
#lr_stat_two_regime <- 2 * (1411.6477 - 1396.5096)
#lr_stat_two_regime
## Find chi-squared critical value for 10 degrees of freedom
#qchisq(0.99, 2)
## Test if likelihood ratio test statistic is greater than critical value
#lr_stat_two_regime > qchisq(0.99, 2)
## Calculate p-value of test
#1 - pchisq(lr_stat_two_regime, 2)
```



## effects
```{r}
#spatialreg::impacts(preg1_fe, listw = listw3nn, time = 8)
```

## Summary