---
title: "results"
author: "Jialiang"
date: "2023-03-27"
output: html_document
---

## Preparation

### R setup

Load the packages we will be using in this document.
```{r pkgs}
## Load and install the R packages we might will be using.
pacman::p_load(sf, tidyverse, magrittr, data.table, hrbrthemes, zoo, GWmodel, spatialreg, spdep, plm, splm, pspatreg, zoo, chatgpt, xlsx)
```

Some data wrangling work.
```{r }
# Replace the absolute path of the `cities_included.shp` file on your computer. 
# Drag the file to terminal (command + space, then search `terminal` on spotlight) if you are in mac, the path will appear.
ct_shape <- st_read("/Users/jialiangchen/Documents/spmodeltoruism/shapefiles/china_second_level_admin_shape/cities_included.shp")
## Import more data.
## change the absolute path on your computer, same as above
ct_data <- read.csv("/Users/jialiangchen/Documents/spmodeltoruism/data/dataforR.csv")
## Perform a left join for our datasets.
ct_spdata_wide <- left_join(
  ct_shape %>% select(NL_NAME_2, geometry) %>% rename(城市shapefile = NL_NAME_2),  
  ct_data,
  by = "城市shapefile"
)

## Reshape our data to long(tidy) form.
ct_spdata_long <- ct_spdata_wide %>% 
  pivot_longer(
    cols = tarl_2011:grnld_2019,
    names_to = c(".value", "year"),
    names_pattern = "(.+)_(.+)"
  )

## Create average tourist expenditure variable in RMBs
ct_spdata_long %<>% 
  mutate(
    tavexp =  (trev/tarl)*1000,
    dmavexp = (dmrev/dmarl)*1000
  )

## Some place has zero international arrival
## Avoid division by zero
ct_spdata_long %<>% 
  mutate(
    inavexp = case_when(
     inarl > 0 ~  (inrev/inarl)*7*1000,
     inarl == 0 ~  0
    )
  )


## Create average tourist expenditure variable in RMBs## Convert the "human" variables from 10 thousands to thousands, just for consistency 
ct_spdata_long %<>%
  mutate(emphotel = emphotel * 10,
         pop = pop * 10
  )

## linear interpolation to deal with missing values
ct_spdata_long %<>%
        mutate(across(c(tarl:inavexp), \(x) zoo::na.approx(x, rule = 2))) 

## check if there are still NA left
sum(is.na(ct_spdata_long))

## set tell R it is a panel
ct_spdata_long <- pdata.frame(ct_spdata_long, index = c("城市shapefile", "year"))
## summarize the data
summary(ct_spdata_long)
```


### Data description

Our data sets contains the data for 283 prefectual-level cities in China from 2011-2019. The following variables are included. 

* `城市shapefile` are the names of the cities in Chinese. Note that it is useful to have chinese names here, as the names in English `City` is incapable of distinguishing the city Fuzhou from Jiangxi province and the city Fuzhou from Fujian province. So make sure to use the chinese version whenever you want to do some macthing/identification/merging work.

* The `Lat` and `Long` variables give the latitude and longitude of these cities. `Geometry` is unique in the `sf` object, it stores the geographical information. 

* `tarl`, `dmarl` and `inarl` are total tourist arrivals, domestic tourist arrivals and international tourist arrivals in thousands, resp.  `trev`, `dmrevl` and `inrev` are total tourism revenue, domestic revenue and international tourism revenue in millions of RMBs (and dollars for the international revenue), resp. 

* __costs__ `tavexp`, `dmavexp` and `inavexp` are the average tourist expenditure in the total, domestic and international level, resp (They are measured in RMB). 

* __price level__ `CPIpy` and `CPI11` are CPI indexes with the base of the preceeding year and 2011, respectively. `hprice` is the price of residential houses (in RMB/m2) in that city. 

* __tourism attractiveness__ `emphotel` is the number of employees in the hotel and catering industry (in thousands).  `spot5A` is then number of "5A" tourism spots. `scenum` is the number of scenic spots.  `grnld` is the green coverage measured in 10,000 square meters.

* __economic development__ `GDPpc` is the GDP per capita in RMB. `slry` is the local salary in RMB. `terti` is the percent of the tertiary industry in the total economy.

* __transportation convenience__ `road` measures the area of roads in million square meters. `bus`, `taxi`, `hotel` are the numbers of oeprating buses, taxis and hotels with star ratings in the city. `subnum` is the number of subway stations in the city.

* __general infrastructure and openness__ `invest` is the total investment in fixed assets in 10 thousands RMB, `forncap` is the actual use of foreign capital in 10 thousands of dollars. 

* __others__ `pop` is the population in the city in thousands. `area` measures the administrative area of the city in square kilometers. 

We first construct a weighting matrix using 8 nearest neighbors. The optimal number of neighbors will be tested later.

### Weighting matrix

```{r, results="hide"}
## deprecated. 8nn may be too large.
## Identify coordinates of the centroid of the multipolygon
## coords <- st_centroid(st_geometry(ct_spdata_wide))

## Create our 8 NN matrix
## Note that the latitude and longitude are handled using great circle distances
## R2 distances will be inaccurate
## knn8W <- knearneigh(coords, k = 8)

## Convert our knn object to neighborhood list
## list8nn <- knn2nb(knn8W)
## Convert to a matrix object
## matrix8nn <- spdep::nb2mat(list8nn)
## Convert our neighborhood list to an listw object
## listw8nn <- spdep::nb2listw(list8nn) 
## Plot the neighborhood relationships
## plot(list8nn, coords)
```

```{r, results="hide"}
## Identify coordinates of the centroid of the multipolygon
coords <- st_centroid(st_geometry(ct_spdata_wide))

## Create our 3,4,5,6 NN matrix
## Note that the latitude and longitude are handled using great circle distances
## R2 distances will be inaccurate
knn3W <- knearneigh(coords, k = 3)
knn4W <- knearneigh(coords, k = 4)
knn5W <- knearneigh(coords, k = 5)
knn6W <- knearneigh(coords, k = 6)

## Convert our knn objects to neighborhood list
list3nn <- knn2nb(knn3W)
list4nn <- knn2nb(knn4W)
list5nn <- knn2nb(knn5W)
list6nn <- knn2nb(knn6W)

## Convert to a matrix object
matrix3nn <- spdep::nb2mat(list3nn)
matrix4nn <- spdep::nb2mat(list4nn)
matrix5nn <- spdep::nb2mat(list5nn)
matrix6nn <- spdep::nb2mat(list6nn)

## Convert our neighborhood list to an listw object
listw3nn <- spdep::nb2listw(list3nn) 
## Plot the neighborhood relationships
# plot(list4nn, coords)
```

```{r}
## Neighbourhood contiguity by distance
d100nb <- dnearneigh(coords, 0, 100)
d150nb <- dnearneigh(coords, 0, 150)
d200nb <- dnearneigh(coords, 0, 200)
summary(d200nb)

## convert them to matrix
d100nb %>% spdep::nb2mat(zero.policy = TRUE) -> matrixd100nb
d150nb %>% spdep::nb2mat(zero.policy = TRUE) -> matrixd150nb
d200nb %>% spdep::nb2mat(zero.policy = TRUE) -> matrixd200nb
```

```{r}
## Create another weighting matrix based on contiguity relations (queen).
ct_spdata_wide %>% spdep::poly2nb("geometry") %>% 
  spdep::nb2mat(zero.policy = TRUE) -> matrixcont

ct_spdata_wide %>% spdep::poly2nb("geometry") %>%  spdep::nb2listw(zero.policy = TRUE) -> listwnb
```

Create spatial lagged variables.
```{r}
## Create spatial lag for some variables

lagGDPpc <- slag(ct_spdata_long$GDPpc, listw = listw3nn) %>% as.numeric( )

ct_spdata_long$lagGDPpc <- lagGDPpc

lagslry <- slag(ct_spdata_long$slry, listw = listw3nn) %>% as.numeric( )

ct_spdata_long$lagslry <- lagslry

lagtarl <- slag(ct_spdata_long$tarl, listw = listw3nn) %>% as.numeric( )

ct_spdata_long$lagtarl <- lagtarl

lagpop <- slag(ct_spdata_long$pop, listw = listw3nn) %>% as.numeric( )

ct_spdata_long$lagpop <- lagpop

lagterti <- slag(ct_spdata_long$terti, listw = listw3nn) %>% as.numeric( )

ct_spdata_long$lagterti <- lagterti

laginvest <- slag(ct_spdata_long$invest, listw = listw3nn) %>% as.numeric( )

ct_spdata_long$laginvest <- laginvest

lagtaxi <- slag(ct_spdata_long$taxi, listw = listw3nn) %>% as.numeric( )

ct_spdata_long$lagtaxi <- lagtaxi

laghotel <- slag(ct_spdata_long$hotel, listw = listw3nn) %>% as.numeric( )

ct_spdata_long$laghotel <- laghotel

lagspot5A <- slag(ct_spdata_long$spot5A, listw = listw3nn) %>% as.numeric( )

ct_spdata_long$lagspot5A <- lagspot5A

laggrnld <- slag(ct_spdata_long$grnld, listw = listw3nn) %>% as.numeric( )

ct_spdata_long$laggrnld <- laggrnld

lagtavexp <- slag(ct_spdata_long$tavexp, listw = listw3nn) %>% as.numeric( )

ct_spdata_long$lagtavexp <- lagtavexp

```

## Use time lag, log transform.

```{r}
tlaged_logged_ct_spdata_long <- ct_spdata_long

## Use the independent variables from the previous year
for (i in 7:ncol(tlaged_logged_ct_spdata_long)) {
  tlaged_logged_ct_spdata_long[[i]] <- lag(tlaged_logged_ct_spdata_long[[i]], 1)
}
summary(tlaged_logged_ct_spdata_long)
## Drop all observations with missing values 
tlaged_logged_ct_spdata_long <- na.omit(tlaged_logged_ct_spdata_long)

## Transfer all variables to log scale
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
  mutate(across(c(tarl:inrev, hprice:road, invest:lagpop, laginvest:lagtavexp), \(x) log(x+1)))

summary(tlaged_logged_ct_spdata_long)
```
  
## Create indicators using different variables
```{r}
## Create indicators using total arrivals
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(
     indicator_tarl = case_when(
      tarl >= lagtarl ~  1,
      tarl < lagtarl ~ 0
     )
   )

## Create indicators using GDP per capita
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(
     indicator_gdp = case_when(
      GDPpc >= lagGDPpc ~  1,
      GDPpc < lagGDPpc ~ 0
     )
   )

## percentage GDP gap
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(GDP_percent = (GDPpc - lagGDPpc) / lagGDPpc)

summary(tlaged_logged_ct_spdata_long$GDP_percent)

## -10 prcent GDP
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(
     indicator_gdpne10 = case_when(
      GDP_percent >= -0.10 ~  1,
      GDP_percent < -0.10 ~ 0
     )
   )

## -5 prcent GDP
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(
     indicator_gdpne5 = case_when(
      GDP_percent >= -0.05 ~  1,
      GDP_percent < -0.05 ~ 0
     )
   )

## 5 prcent GDP
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(
     indicator_gdpps5 = case_when(
      GDP_percent >= 0.05 ~  1,
      GDP_percent < 0.05 ~ 0
     )
   )

## 10 prcent GDP
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(
     indicator_gdpps10 = case_when(
      GDP_percent >= 0.1 ~  1,
      GDP_percent < 0.1 ~ 0
     )
   )

## [-0.05, 0] percent GDP
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(
     indicator_gdpne5to0 = case_when(
      GDP_percent >= -0.05 & GDP_percent <= 0 ~  1,
      GDP_percent < -0.05 | GDP_percent > 0  ~ 0
     )
   )

## [0, 0.05] percent GDP
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(
     indicator_gdp0tops5 = case_when(
      GDP_percent >= 0 & GDP_percent <= 0.05 ~  1,
      GDP_percent < 0 | GDP_percent > 0.05  ~ 0
     )
   )

## (0.05, 0.1) percent GDP
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(
     indicator_gdpps5to10 = case_when(
      GDP_percent >= 0.05 & GDP_percent <= 0.1 ~  1,
      GDP_percent < 0.05 | GDP_percent > 0.1  ~ 0
     )
   )

## Create indicators using number of hotels
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(
     indicator_hotel = case_when(
      hotel >= laghotel ~  1,
      hotel < laghotel ~ 0
     )
   )

## Create indicators using number of 5A spots
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(
     indicator_5A = case_when(
      spot5A >= lagspot5A ~  1,
      spot5A < lagspot5A ~ 0
     )
   )

## Create indicators using third industry development level
tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   mutate(
     indicator_terti = case_when(
      terti >= lagterti ~  1,
      terti < lagterti ~ 0
     )
   )

summary(tlaged_logged_ct_spdata_long)
```


```{r}
# 
# tlaged_logged_ct_spdata_long %>%
#    as.data.frame() %>%
#    select(!geometry) %>%
#    arrange(year, 城市shapefile)  %>%
#  xlsx::write.xlsx2("/Users/jialiangchen/Documents/spmodeltoruism/codes/tworegime/tlaged_logged_ct_spdata_long.xlsx")
#  
#  ## output weight matrix (4nn)
#  matrix4nn %>% as.data.frame() %>% write.xlsx2("/Users/jialiangchen/Documents/spmodeltoruism/codes/tworegime/4nnmatrix.xlsx")
```

## Model tests

We will be mainly operating on `tlaged_logged_ct_spdata_long`.

1. **combo0**:
```{r}
formula0 <- tarl ~ GDPpc + slry + pop + terti + invest + taxi + hotel + spot5A + grnld + tavexp + lagGDPpc + lagslry + lagpop + lagterti + laginvest + lagtaxi + laghotel + lagspot5A + laggrnld + lagtavexp
```

2. **combo1**:

remove population variable as they may not be significant.

```{r}
formula1 <- tarl ~ GDPpc + slry + terti + invest + taxi + hotel + spot5A + grnld + tavexp + lagGDPpc + lagslry + lagterti + laginvest + lagtaxi + laghotel + lagspot5A + laggrnld + lagtavexp
```

## Panel regressions

### Maximum likelihood estimation, pooled, lag model

```{r}
preg0 <- spml(formula = formula0, data = tlaged_logged_ct_spdata_long, index = c("城市shapefile", "year"), listw = listw3nn, model = "pooling", lag = TRUE, spatial.error = "none")
summary(preg0)
```

### Maximum likelihood estimation, one regime

```{r}
##index = c("城市shapefile", "year")
## FE individual
preg1_fe_ind <- spml(formula = formula0, data = tlaged_logged_ct_spdata_long, listw = listw3nn, model = "within", effect = "individual", lag = TRUE, spatial.error = "none")

## FE time
preg1_fe_time <- spml(formula = formula0, data = tlaged_logged_ct_spdata_long, listw = listw3nn, model = "within", effect = "time", lag = TRUE, spatial.error = "none")

## FE twoway
preg1_fe <- spml(formula = formula0, data = hy_tlaged_logged_ct_spdata_long, listw = listw3nn, model = "within", effect = "twoway", lag = TRUE, spatial.error = "none")

## insignificant spatial effects. This is due to the estimation of individual fixed effects - we only use 8 years for each unit to estimate.

## see what if we estimate the random effect model
preg1_re <- spml(formula = formula0, data = hy_tlaged_logged_ct_spdata_long, index = c("城市shapefile", "year"), listw = listw3nn, model = "random", lag = TRUE, spatial.error = "none")

summary(preg1_fe_ind)
summary(preg1_fe_time)
summary(preg1_fe)
summary(preg1_re)
```

## Hypotheses tests

### LR test for fixed effects
```{r}
## Calculate likelihood ratio test statistics for individaul fe
lr_stat_ind_fe <- 2 * (preg1_fe_ind$logLik - preg0$logLik)
lr_stat_ind_fe
## Find chi-squared critical value for 282 degrees of freedom
qchisq(0.99, 282)
## Test if likelihood ratio test statistic is greater than critical value
lr_stat_ind_fe > qchisq(0.99, 282)
## Calculate p-value of test
1 - pchisq(lr_stat_ind_fe, 282)

## Calculate likelihood ratio test statistics for time fe
lr_stat_time_fe <- 2 * (preg1_fe_time$logLik - preg0$logLik)
lr_stat_time_fe
## Find chi-squared critical value for 282 degrees of freedom
qchisq(0.999, 7)
## Test if likelihood ratio test statistic is greater than critical value
lr_stat_time_fe > qchisq(0.999, 7)
## Calculate p-value of test
1 - pchisq(lr_stat_ind_fe, 282)
```


### Test for spatial dependence

$H_{0}:$ No random effect, no spatial autocorrelation
```{r}
bsktest(formula0, data = tlaged_logged_ct_spdata_long, listw = listw3nn, index = c("城市shapefile", "year"), test = "LMH")
```
$H_{0}:$ spatial autocorrelation
```{r}
bsktest(formula0, data = tlaged_logged_ct_spdata_long, listw = listw3nn, index = c("城市shapefile", "year"), test = "CLMlambda")
```
$H_{0}:$ random effect
```{r}
bsktest(formula0, data = tlaged_logged_ct_spdata_long, listw = listw3nn, index = c("城市shapefile", "year"), test = "CLMmu")
```

### Test between fixed effects model and random effect model (Hausman test)

```{r}
## $H_{0}:$ The preferred model is Random Effect
sphtest(x = formula0, data = tlaged_logged_ct_spdata_long, listw = listw3nn, index = c("城市shapefile", "year"), spatial.model = "lag", method = "ML")
```

1. These tests are panel versions of the locally robust LM test for spatial dependence of Anselin (1996).
```{r}
slmtest(formula = formula0, data = tlaged_logged_ct_spdata_long, listw = listw3nn, index = c("城市shapefile", "year"), model = "within", test = "rlme")
```
```{r}
slmtest(formula = formula0, data = tlaged_logged_ct_spdata_long, listw = listw3nn, index = c("城市shapefile", "year"), model = "within", test = "rlml")
```

This points us to the spatial lag model.

### Test for normality, serial dependence, and homoskedasticity

```{r}
# rearrange data so that they are stacked as [city1,...,city283 ] in year 1, then  [city1,...,city283 ] in year 2 ...
stacked_tlaged_logged_ct_spdata_long <- tlaged_logged_ct_spdata_long %>%
   arrange(year, 城市shapefile)
## import and wrange regression results data
results <- read.xlsx("/Users/jialiangchen/Documents/spmodeltoruism/codes/tworegime/results.xlsx", 1) %>% data.table::transpose(make.names = "OriginalVariableNames") %>% mutate(城市shapefile = stacked_tlaged_logged_ct_spdata_long$城市shapefile) %>% select(c("城市shapefile", "y", "yhat", "resid")) 

## take a look of the results
str(results)
## our cols are coerased into characters, we need to bring them back to numeric values
results[c("y", "yhat", "resid")] <- map(results[c("y", "yhat", "resid")], as.numeric)
## check we did it correct
sum(results$y == stacked_tlaged_logged_ct_spdata_long$tarl) # should be 2264
str(results)

## To test for normality, we need to first standardize the redisuals
results <- results %>% mutate(standized_resid = resid / sd(resid))
## kdensity plot of the redisual
resid_plot <- ggplot(data = results, aes(x = standized_resid)) + 
  geom_density() 
resid_plot
## Q-Q plot
qq_residuals <- ggplot() +
  geom_abline(color = "red") +
  geom_qq(aes(sample = results$standized_resid)) +
  geom_vline(xintercept = c(-2, 2), linetype="dotted", 
                color = "blue", size=1) +
  coord_fixed()
qq_residuals

normality_test <- results %>% filter(standized_resid >= -2 & standized_resid <= 2) %>% select(standized_resid)  %>% unlist() %>% ols_test_normality()

normality_test 
```


### Hausman test
```{r}
sphtest(preg1_fe, preg1_re)
## sphtest(preg2_fe, preg2_re)
```
## effects
```{r}
spatialreg::impacts(preg1_fe, listw = listw4nn, time = 8)
```

## Summary