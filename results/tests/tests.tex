\documentclass[11pt,a4paper]{amsart}
\usepackage{setspace}
\doublespacing
\usepackage{amssymb,latexsym}
\usepackage{graphicx}
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{lemma}{Lemma}
\newtheorem{axiom}{Axiom}
\newtheorem{proposition}{Proposition}
\usepackage{geometry}
\geometry{a4paper,left=2cm,right=2cm,top=1cm,bottom=1cm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
% \usepackage{ulem} % various underlines
\usepackage{hyperref} % to insert URL 
\usepackage{graphicx} % to insert illustration
\usepackage[mathscr]{eucal} % to express a collection of sets
\usepackage{bm} % bold font in equation environment
\usepackage{color} % color some text
\usepackage{framed} % to add a frame 
\usepackage{tikz}
\usepackage{tabularx} 
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
		\node[shape=circle,draw,inner sep=1pt] (char) {#1};}} % circled numbers
\usepackage{float}%do not auto repositioning
% $\uppercase\expandafter{\romannumeral1}$ Roman numeral
%	\begin{figure}[hbt]
	%{\centering \includegraphics[scale=0.78]{ring_algebra_semi}}
	%\caption{ring \& algebra \& semi-}\label{F:ring_algebra_semi}
	%\end{figure}
\usepackage[style=apa, eprint=false]{biblatex} %Imports biblatex package
\addbibresource{specms.bib} %Import the bibliography file
	
\begin{document}
\title{the bouquet of tests}
\date{\today}
\maketitle
\tableofcontents
\newpage
		
\section {Specification tests}
\subsection{Likelihood ratio tests for fixed effects. }\hfill\par
		
\textit{The likelihood ratio test} compares the log-likelihood of the unrestricted model with that of the restricted mode. The rationale is that if the null hypotheses are true, then these values should be close. The likelihood ratio test statistics is 
\[	-2 \ln \lambda = 2(\ln L(\hat{\theta}_{U}) - \ln L(\hat{\theta}_{R}) ),	\]
where $\hat{\theta}_{U}$ is the maximum likelihood estimate of the \emph{unrestricted} model, $\hat{\theta}_{R}$ is the maximum likelihood estimate of the \emph{restricted} model, and $\lambda$ is the likelihood ratio, defined as $\lambda = L(\hat{\theta}_{R}) / L(\hat{\theta}_{U})$.
		
This test statistic is distributed $\chi^{2}$ with degrees of freedom equal to the number of model restrictions. That is,
	\[	-2 \ln \lambda \sim \chi^{2}(J).	\]
		
$\bullet$ \textbf{$H_{0}:$ Spatial fixed effects are not jointly significant.} 
		
There are $283$ units in our data, the test statistic is distributed  $-2 \ln \lambda \sim \chi^{2}(282).$
		
The null hypothesis is 
\[	H_{0}: \begin{pmatrix}
		\mu_{1} \\
		\dots \\
		\mu_{283}
\end{pmatrix} = \begin{pmatrix}
		0 \\
		\dots \\
		0
\end{pmatrix}.	\]
		
The test statistic takes the value $6069.595$, which is much larger than the critical value for a $99.9\%$ confidence interval ($361.1201$). We reject the null hypothesis,  with a p-value less than $0.001$.

$\bullet$ \textbf{$H_{0}:$ Time fixed effects are not jointly significant.} 
		
There are $8$ time periods in our data, the test statistic is distributed  $-2 \ln \lambda \sim \chi^{2}(7).$
		
The null hypothesis is 
\[	H_{0}: \begin{pmatrix}
		\lambda_{1} \\
		\dots \\
		\lambda_{8}
\end{pmatrix} = \begin{pmatrix}
		0 \\
		\dots \\
		0
\end{pmatrix}.	\]
		
The test statistic takes the value $74.08778$, which is much larger than the critical value for a 99.9\% confidence interval ($24.32189$). We reject the null hypothesis, with a p-value less than $0.001$.
		
These results justify the usage of individual and time fixed effects. 
		
\subsection{Lagrange multiplier tests for spatial effects.}\footnote{Tests for spatial dependence in panel models by \parencite{anselinSpatialPanelEconometrics2008}.}\hfill\par
		
\subsection{Normality of the regression residuals}\hfill\par

Our maximum likelihood estimation depends on the assumption that $\epsilon_{it}$ is i.i.d. normally distributed. We can get some clues about this assumption by looking at the residuals. Here I am using the residuals of the two-regime regression and 3nn weighting matrix. 

By plotting the kernel density of the residuals, it seems like that we have a higher-than-normal kurtotics. It is pretty symmetric, so it is not ``skewed'', but it has heavy tails.

\begin{figure}[hbt]
	{\centering \includegraphics[scale=0.78]{/Users/jialiangchen/Documents/spmodeltoruism/results/resid_plot.pdf}}
	\caption{Kernel density of the residual}\label{F:kden_resid}
\end{figure}

This is the Q-Q plot of the standardized residuals.
\begin{figure}[hbt]
	{\centering \includegraphics[scale=0.78]{/Users/jialiangchen/Documents/spmodeltoruism/results/qq_residuals.pdf}}
	\caption{Q-Q plot of the residual}\label{F:qq_residuals}
\end{figure}

If the residual is actually distributed normally, the dots should fit the red line well. It is argued that with a large sample, it is more important to focus on the standardized residuals within the range $[-2, 2]$. This is because these tests are tend to over-reject the null when  sample size is large.  In the tails, due to lower density, deviations (from the normal distribution) are expected but not of concern. As you can see, most of our residuals within $[-2, 2]$ fits the line quite well. Only a limited number of them outside that range deviates from the red line.

We can also test this formally. But this kind of test should be taken with a grain of salt.\footnote{See \href{https://stats.stackexchange.com/questions/2492/is-normality-testing-essentially-useless}{here} for a discussion on this issue.} We use Kolmogorov–Smirnov test for the test of normality. If we focus on this range of $[-2, 2]$ (with $2141$ out of $2264$ observations), we have the following test results.

$\bullet$ \textbf{$H_{0}:$ The econometric residuals are drawn from a normal distribution.} 

The Kolmogorov–Smirnov test statistic is  $0.0258$ with a p-value of $0.1158$. There is not enough evidence to reject the assumption of normally distributed residuals. 

\subsection{Sequential correlation of the regression residuals}\hfill\par

The tests for serial correlation in the residuals for our spatial panel model with two-way fixed effects and two endogenous spatial lags is not well developed. The plots give some intuition.

\begin{figure}[hbt]
	{\centering \includegraphics[scale=0.78]{/Users/jialiangchen/Documents/spmodeltoruism/results/corr_resid.pdf}}
	\caption{The serial correlation of residuals}\label{F:corr_resid}
\end{figure}

Following the practice of \parencite{elhorstEvidencePoliticalYardstick2009a}, I tested the evidence of serial correlation in the residuals using time series data for each observations. The test is based on Yule-Walker Estimate. For each observation, we test the null of purely random time series. The result indicates that for $23\%$ percent of the cities, we must reject the null. 

Note that this test relies on the normality of error term. But as we tested the normality before, we should be fine. 

\subsection{Spatial correlation of the regression residuals}\hfill\par

This tests for if there are any remaining spatial correlation in the residuals. The Lagrange multiplier test is conducted here.

$\bullet$ \textbf{$H_{0}:$ There is no spatial correlation in the econometric residuals.} 

The LM statistic is $0.035654$, we have no evidence against the null, with a p-value $= 0.8502$. 

\subsection{Homoskedasticity of the regression residuals}\hfill\par
A violation of homoscedasticity is indicated by a non-flat fitted line of a scale-location plot.  We fail to find evidence of heteroskedasticity. LM = 16.031, df = 1, p-value = 6.232e-05

\begin{figure}[hbt]
	{\centering \includegraphics[scale=0.78]{/Users/jialiangchen/Documents/spmodeltoruism/results/hmsk.pdf}}
	\caption{The scale-location plot for standardized residuals}\label{F:hmsk}
\end{figure}

I use the Breusch-Pagan test to assess homoscedasticity formally. The Breusch-Pagan test regresses the residuals on the fitted values or predictors and checks whether they can explain any of the residual variance. A small p-value, then, indicates that residual variance is non-constant (heteroscedastic). 

The Breusch-Pagan test statistics in our model is about $0.10$ with a p-value of $0.74$. We have no evidence to reject the null of homoskedasticity.

\subsection{Multicollinearity}\hfill\par
Below are the the variance inflation factors (VIF) for the explanatory variables. It contains information about the extent of similarity between explanatory variables, as well as how much standard error is increased due to multicollinearity.  A value below $5$ indicates that we are good.
\begin{table}[H]
	\centering % Center the table
	\begin{tabularx}{\textwidth}{|X|X|X|X|X|X|X|X|X|X|}
		\hline
		GDPpc   &  slry    &  pop &   terti &  invest  &   taxi   &  hotel &  spot5A   &  grnld &  tavexp \\
	\hline
	4.073864& 2.333043  & 4.747088 & 2.167909 & 5.267853 & 2.394111 & 1.976621 & 1.510278 & 3.763018 & 1.569254 \\
		\hline
	\end{tabularx}
\end{table}

\subsection{Spatially lagged dependent variable and error autocorrelation}\hfill\par

This is a LM test for a spatially lagged dependent variable and error autocorrelation using panel data. (Departing from non-spatial models).

$\blacksquare$ If we do not include the spatial lag independent variables, the results are as follows. 

$\bullet$ \textbf{$H_{0}:$ No spatial lag dependence.} 

We get a LM statistic $= 97.412$, we reject the null with a  p-value $< 2.2e-16$. 

$\bullet$ \textbf{$H_{0}:$ No spatial error dependence.} 

We get a LM statistic $= 15.802$, we reject the null with a  p-value $= 7.032e-05$. 

\vspace{5pt}

$\blacksquare$ If we include the spatial lag independent variables, the results are as follows.

$\bullet$ \textbf{$H_{0}:$ No spatial lag dependence.} 

We get a LM statistic $= 19.43$, we reject the null with a  p-value $= 1.044e-05$. 

$\bullet$ \textbf{$H_{0}:$ No spatial error dependence.} 

We get a LM statistic $= 13.141$, we reject the null with a  p-value $= 0.0002889$. 

Note that these are the results if we do not control for the time fixed effects. After we controlling for the time fixed effect, there is no more evidence of spatial correlation in the residual term, as we shown earlier. The test statistics are both significantly higher for the spatial lag term than the error term.

\subsection{Spatially lagged independent variables}\hfill\par

Likelihood ratio test of whether the spatially lagged independent variables are significant.

$\bullet$ \textbf{$H_{0}:$ The spatially lagged independent variables are jointly significant.} 

We get a LR statistic $= 118.2782$, we reject the null with a  p-value $< 0.01$. 

\subsection{Random effects and fixed effects}\hfill\par

Lagrange Multiplier test for random effect.

$\bullet$ \textbf{$H_{0}:$ No random effect.}

The test statistics is LM*-mu $= 78.357$, we reject the null with a p-value $< 2.2e-16$.

Hausman test for random effect assumption.

$\bullet$ \textbf{$H_{0}:$ The preferred model is Random Effect.}

The test statistics is chisq $= 79.657$, we reject the null with a p-value $= 5.862e-13$.

\section{Hypothesis testing}\hfill\par

\subsection{Difference between two regimes}\hfill\par

Likelihood ratio test of the difference between parameters for two regimes.

$\bullet$ \textbf{$H_{0}:$ There is no significant difference between two regimes.}

The test statistics is chisq $= 30.2762$ with df $= 2$, we reject the null with a p-value $= 2.664445e-07$. Therefore, we reject the single-regime model in favor of the two-regime model.


\printbibliography

\end{document}
